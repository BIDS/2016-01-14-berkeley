<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="generator" content="pandoc">
    <title>Software Carpentry: Testing</title>
    <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="stylesheet" type="text/css" href="css/bootstrap/bootstrap.css" />
    <link rel="stylesheet" type="text/css" href="css/bootstrap/bootstrap-theme.css" />
    <link rel="stylesheet" type="text/css" href="css/swc.css" />
    <link rel="alternate" type="application/rss+xml" title="Software Carpentry Blog" href="http://software-carpentry.org/feed.xml"/>
    <meta charset="UTF-8" />
    <!-- HTML5 shim, for IE6-8 support of HTML5 elements -->
    <!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body class="lesson">
    <div class="container card">
      <div class="banner">
        <a href="http://software-carpentry.org" title="Software Carpentry">
          <img alt="Software Carpentry banner" src="img/software-carpentry-banner.png" />
        </a>
      </div>
      <article>
      <div class="row">
        <div class="col-md-10 col-md-offset-1">
          <h1 class="title">Testing</h1>
          <h2 class="subtitle">Running Tests with Nose</h2>
<section class="objectives panel panel-warning">
<div class="panel-heading">
<h2><span class="glyphicon glyphicon-certificate"></span>Learning Objectives</h2>
</div>
<div class="panel-body">
<ul>
<li>Understand how to run a test suite using the nose framework</li>
<li>Understand how to read the output of a nose test suite</li>
</ul>
</div>
</section>
<p>We created a suite of tests for our mean function, but it was annoying to run them one at a time. It would be a lot better if there were some way to run them all at once, just reporting which tests fail and which succeed.</p>
<p>Thankfully, that exists. Recall our tests:</p>
<pre class="sourceCode python"><code class="sourceCode python"><span class="ch">from</span> mean <span class="ch">import</span> *

<span class="kw">def</span> test_ints():
    num_list = [<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>]
    obs = mean(num_list)
    exp = <span class="dv">3</span>
    <span class="kw">assert</span> obs == exp

<span class="kw">def</span> test_zero():
    num_list=[<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">4</span>,<span class="dv">6</span>]
    obs = mean(num_list)
    exp = <span class="dv">3</span>
    <span class="kw">assert</span> obs == exp

<span class="kw">def</span> test_double():
    <span class="co"># This one will fail in Python 2</span>
    num_list=[<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>]
    obs = mean(num_list)
    exp = <span class="fl">2.5</span>
    <span class="kw">assert</span> obs == exp

<span class="kw">def</span> test_long():
    big = <span class="dv">100000000</span>
    obs = mean(<span class="dt">range</span>(<span class="dv">1</span>,big))
    exp = big/<span class="fl">2.0</span>
    <span class="kw">assert</span> obs == exp

<span class="kw">def</span> test_complex():
    <span class="co"># given that complex numbers are an unordered field</span>
    <span class="co"># the arithmetic mean of complex numbers is meaningless</span>
    num_list = [<span class="dv">2</span> + 3j, <span class="dv">3</span> + 4j, -<span class="dv">32</span> - 2j]
    obs = mean(num_list)
    exp = <span class="ot">NotImplemented</span>
    <span class="kw">assert</span> obs == exp</code></pre>
<p>Once these tests are written in a file called <code>test_mean.py</code>, the command “nosetests” can be called from the directory containing the tests:</p>
<pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="kw">nosetests</span></code></pre>
<pre class="output"><code>....F
======================================================================
FAIL: test_mean.test_complex
----------------------------------------------------------------------
Traceback (most recent call last):
  File &quot;/Users/khuff/anaconda/envs/py3k/lib/python3.3/site-packages/nose/case.py&quot;, line 198, in runTest
    self.test(*self.arg)
  File &quot;/Users/khuff/repos/2015-06-04-berkeley/testing/test_mean.py&quot;, line 34, in test_complex
    assert obs == exp
AssertionError

----------------------------------------------------------------------
Ran 5 tests in 3.746s

FAILED (failures=1)</code></pre>
<p>In the above case, the python nose package ‘sniffed-out’ the tests in the directory and ran them together to produce a report of the sum of the files and functions matching the regular expression <code>[Tt]est[-_]*</code>.</p>
<p>The major boon a testing framework provides is exactly that, a utility to find and run the tests automatically. With <code>nose</code>, this is the command-line tool called <em>nosetests</em>. When <em>nosetests</em> is run, it will search all the directories whose names start or end with the word <em>test</em>, find all of the Python modules in these directories whose names start or end with <em>test</em>, import them, and run all of the functions and classes whose names start or end with <em>test</em>. In fact, <code>nose</code> looks for any names that match the regular expression <code>'(?:^|[\\b_\\.-])[Tt]est'</code>. This automatic registration of test code saves tons of human time and allows us to focus on what is important: writing more tests.</p>
<p>When you run <em>nosetests</em>, it will print a dot (<code>.</code>) on the screen for every test that passes, an <code>F</code> for every test that fails, and an <code>E</code> for every test were there was an unexpected error. In rarer situations you may also see an <code>S</code> indicating a skipped tests (because the test is not applicable on your system) or a <code>K</code> for a known failure (because the developers could not fix it promptly). After the dots, <em>nosetests</em> will print summary information.</p>
<section class="challenge panel panel-success">
<div class="panel-heading">
<h2><span class="glyphicon glyphicon-pencil"></span>Fix The Failing Code</h2>
</div>
<div class="panel-body">
<p>Without changing the tests, alter the mean.py file from the previous section until it passes. When it passes, <em>nosetests</em> will produce results like the following:</p>
<pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="kw">nosetests</span></code></pre>
<pre class="output"><code>.....

Ran 5 tests in 3.746s

OK</code></pre>
</div>
</section>
<p>As we write more code, we would write more tests, and <em>nosetests</em> would produce more dots. Each passing test is a small, satisfying reward for having written quality scientific software. Now that you know how to write tests, let’s go into what can go wrong.</p>
<blockquote>
<h2>Key Points</h2>
<ul>
<li>The <code>nosetests</code> command collects and runs tests starting with <code>Test-</code>, <code>test_</code>, and similar names.</li>
<li><code>.</code> means the test passed</li>
<li><code>F</code> means the test failed</li>
<li><code>E</code> encountered an error</li>
<li><code>K</code> is a known failure</li>
<li><code>S</code> is a purposefully skipped test</li>
</ul>
</blockquote>
        </div>
      </div>
      </article>
      <div class="footer">
        <a class="label swc-blue-bg" href="http://software-carpentry.org">Software Carpentry</a>
        <a class="label swc-blue-bg" href="https://github.com/swcarpentry/git-novice">Source</a>
        <a class="label swc-blue-bg" href="mailto:admin@software-carpentry.org">Contact</a>
        <a class="label swc-blue-bg" href="LICENSE.html">License</a>
      </div>
    </div>
    <!-- Javascript placed at the end of the document so the pages load faster -->
    <script src="http://software-carpentry.org/v5/js/jquery-1.9.1.min.js"></script>
    <script src="css/bootstrap/bootstrap-js/bootstrap.js"></script>
  </body>
</html>
